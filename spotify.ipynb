# Spotify Songs' Genre Segmentation - Jupyter Notebook Code
# Paste this in a Jupyter / Colab notebook and run cell-by-cell.
# Requirements: pandas, numpy, matplotlib, scikit-learn, caas_jupyter_tools (optional for display)
# If caas_jupyter_tools is not available, comment out the display_dataframe_to_user calls.

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.neighbors import NearestNeighbors
from math import ceil

# (Optional) helper for nicer DataFrame display in some notebook UIs
try:
    from caas_jupyter_tools import display_dataframe_to_user
    def show_df(name, df_):
        display_dataframe_to_user(name, df_)
except Exception:
    def show_df(name, df_):
        print(f"--- {name} ---")
        display(df_.head(10))

# --- Config ---
DATA_PATH = 'C:\spotify dataset.csv'  # change if needed
OUT_DIR = "spotify_project_outputs"
os.makedirs(OUT_DIR, exist_ok=True)

# --- 1) Load dataset ---
df = pd.read_csv(r"C:\spotify dataset.csv")


print("Loaded dataset shape:", df.shape)

# Quick peek
show_df("Head of dataset", df.head(8))
print("\nColumns:", df.columns.tolist())

# --- 2) Inspect missing values and duplicates ---
print("\nMissing values per column (descending):")
print(df.isnull().sum().sort_values(ascending=False).head(25))
print("\nDuplicate rows count:", df.duplicated().sum())

# Drop duplicates
if df.duplicated().sum() > 0:
    df = df.drop_duplicates().reset_index(drop=True)
    print("Dropped duplicates. New shape:", df.shape)

# --- 3) Cleaning: fill missing values ---
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()

# Fill numeric with median
for c in num_cols:
    if df[c].isnull().any():
        df[c] = df[c].fillna(df[c].median())

# Fill categorical with mode
for c in cat_cols:
    if df[c].isnull().any():
        mode = df[c].mode()
        df[c] = df[c].fillna(mode[0] if len(mode)>0 else "Unknown")

print("Total missing after fill:", df.isnull().sum().sum())

# --- 4) EDA: distributions of audio features ---
preferred_features = ['danceability','energy','loudness','speechiness','acousticness',
                      'instrumentalness','liveness','valence','tempo','duration_ms']
features = [f for f in preferred_features if f in df.columns]
print("Features available for analysis:", features)

# Plot histograms
n = len(features)
cols = 3
rows = ceil(n/cols)
plt.figure(figsize=(4*cols,3*rows))
for i, feat in enumerate(features, 1):
    plt.subplot(rows, cols, i)
    plt.hist(df[feat].dropna(), bins=30)
    plt.title(feat)
plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR, "feature_histograms.png"))
plt.show()

# Top playlist genres / playlist names / top artists
if 'playlist_genre' in df.columns:
    top_genres = df['playlist_genre'].value_counts().head(15)
    show_df("Top playlist genres (counts)", top_genres.reset_index().rename(columns={'index':'playlist_genre', 'playlist_genre':'count'}))
    plt.figure(figsize=(10,4)); plt.bar(top_genres.index, top_genres.values); plt.xticks(rotation=45, ha='right'); plt.title("Top 15 Playlist Genres"); plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR,"top_playlist_genres.png")); plt.show()

if 'playlist_name' in df.columns:
    top_playlists = df['playlist_name'].value_counts().head(15)
    show_df("Top playlist names (counts)", top_playlists.reset_index().rename(columns={'index':'playlist_name','playlist_name':'count'}))
    plt.figure(figsize=(10,4)); plt.bar(top_playlists.index, top_playlists.values); plt.xticks(rotation=45, ha='right'); plt.title("Top 15 Playlist Names"); plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR,"top_playlist_names.png")); plt.show()

artist_col = next((c for c in df.columns if 'artist' in c.lower()), None)
if artist_col:
    top_artists = df[artist_col].value_counts().head(15)
    show_df("Top artists", top_artists.reset_index().rename(columns={'index':artist_col, 0:'count'}))
    plt.figure(figsize=(10,4)); plt.bar(top_artists.index, top_artists.values); plt.xticks(rotation=45, ha='right'); plt.title("Top 15 Artists"); plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR,"top_artists.png")); plt.show()

# --- 5) Correlation matrix ---
num_df = df[features].copy()
corr = num_df.corr()
show_df("Correlation matrix (rounded)", corr.round(3))

plt.figure(figsize=(8,6))
plt.imshow(corr, interpolation='nearest', aspect='auto')
plt.colorbar()
plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)
plt.yticks(range(len(corr.columns)), corr.columns)
plt.title("Correlation matrix")
plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR,"correlation_matrix.png"))
plt.show()

# --- 6) Prepare for clustering ---
X = df[features].values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA for 2D visualization
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)
print("PCA explained variance (2 comps):", pca.explained_variance_ratio_)

plt.figure(figsize=(7,5))
plt.scatter(X_pca[:,0], X_pca[:,1], s=8)
plt.title("PCA projection of songs")
plt.xlabel("PC1"); plt.ylabel("PC2"); plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR,"pca_all_songs.png"))
plt.show()

# --- 7) Choose k: elbow + silhouette ---
sse = []
sil_scores = []
K_range = list(range(2,9))
for k in K_range:
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = km.fit_predict(X_scaled)
    sse.append(km.inertia_)
    sil_scores.append(silhouette_score(X_scaled, labels))

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(K_range, sse, marker='o'); plt.title("Elbow (SSE)"); plt.xlabel("k")
plt.subplot(1,2,2)
plt.plot(K_range, sil_scores, marker='o'); plt.title("Silhouette Score"); plt.xlabel("k")
plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR,"elbow_silhouette.png")); plt.show()

best_k = K_range[int(np.argmax(sil_scores))]
print("Suggested k (by silhouette):", best_k)

# --- 8) Fit final KMeans and assign clusters ---
k_final = best_k if best_k >= 2 else 4
kmeans = KMeans(n_clusters=k_final, random_state=42, n_init=20)
labels = kmeans.fit_predict(X_scaled)
df['cluster'] = labels

# Save results
out_csv = os.path.join(OUT_DIR, "spotify_with_clusters.csv")
df.to_csv(out_csv, index=False)
print("Saved dataset with cluster labels to:", out_csv)

# Cluster summary
cluster_counts = df['cluster'].value_counts().sort_index()
show_df("Cluster sizes", cluster_counts.reset_index().rename(columns={'index':'cluster', 'cluster':'count'}))

# Cluster centers (approx original scale)
centers = scaler.inverse_transform(kmeans.cluster_centers_)
centers_df = pd.DataFrame(centers, columns=features)
show_df("Cluster centers (approx original scale)", centers_df.round(3))

# Visualize clusters on PCA
plt.figure(figsize=(8,6))
for c in sorted(df['cluster'].unique()):
    mask = df['cluster']==c
    plt.scatter(X_pca[mask,0], X_pca[mask,1], s=8, label=f"Cluster {c}")
plt.legend(); plt.title(f"PCA projection colored by KMeans clusters (k={k_final})"); plt.tight_layout()
plt.savefig(os.path.join(OUT_DIR,"pca_clusters.png")); plt.show()

# --- 9) Cluster composition by playlist_genre (if available) ---
if 'playlist_genre' in df.columns:
    cg = df.groupby(['cluster','playlist_genre']).size().reset_index(name='count')
    top5_per_cluster = cg.sort_values(['cluster','count'], ascending=[True,False]).groupby('cluster').head(5)
    show_df("Top 5 playlist_genre per cluster", top5_per_cluster)

# --- 10) Simple recommendation prototype ---
# For a given track index or track_id, recommend nearest songs in same cluster
def recommend_by_track(track_index, n_recs=10):
    # find the cluster
    cl = df.loc[track_index, 'cluster']
    # find songs in same cluster
    cluster_idx = df[df['cluster']==cl].index
    # Use NearestNeighbors on scaled features to find nearest neighbors
    nn = NearestNeighbors(n_neighbors=min(n_recs+1, len(cluster_idx)), metric='euclidean')
    nn.fit(X_scaled[cluster_idx])
    # index of our track inside cluster_idx array
    pos = list(cluster_idx).index(track_index)
    dists, neigh_idx = nn.kneighbors([X_scaled[track_index]])
    # convert indices to original DataFrame indices
    rec_idx = [cluster_idx[i] for i in neigh_idx[0] if cluster_idx[i] != track_index]
    return df.loc[rec_idx].head(n_recs)

# Example: recommend for the first row
print("\nExample recommendations for track index 0:")
display(recommend_by_track(0, n_recs=5)[['track_name','track_artist','playlist_genre','cluster']].head())

# --- 11) Final summary saved for user ---
summary = {
    'Total songs': [len(df)],
    'Features used': [features],
    'Selected k': [k_final],
    'PCA exp var (2 comp)': [list(pca.explained_variance_ratio_.round(3))],
    'Outputs folder': [OUT_DIR]
}
summary_df = pd.DataFrame(summary)
show_df("Project summary", summary_df)
print("All important plots and CSV saved under folder:", OUT_DIR)
